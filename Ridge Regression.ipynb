{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "**I. Weight update steps of stochastic gradient descent (SGD) for linear regression with L2 regularisation norm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loss function with L2 regularisation norm, the error function can be written as,\n",
    "\n",
    "\\begin{align}\n",
    "\\large{E(w) := \\sum_{n} E_{n}(w) +\\frac{\\lambda}{2}{w^2} \\small{\\quad\\textrm{ where }\\quad} \\large{E_{n}(w) := {\\frac{1}{2}}(t_{n} - w^T\\phi(x_{n}))^2}}\n",
    "\\end{align}\n",
    "\n",
    "so the gradient can be computed as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\large{\\nabla({E_{n}}(w) + \\frac{\\lambda}{2}{w^2}) := \\nabla({E_{n}}(w) + \\nabla(\\frac{\\lambda}{2}{w^2})} \\\\\n",
    "\\large{:= -\\phi(x_{n})(t_{n} - w^T\\phi(x_{n})) +{w}{\\lambda}}\n",
    "\\end{align*}\n",
    "\n",
    "After presentation of the $n$th training datapoint, the stochastic gradient descent algorithm updates the parameter vector $w$ using,\n",
    "\n",
    "\\begin{align}\n",
    "\\large{\\textbf{w}^{(\\tau)} = \\textbf{w}^{(\\tau-1)} - {\\eta}^{(\\tau)}{\\nabla} (E_{n}(\\textbf{w}^{(\\tau)})+ \\frac{\\lambda}{2}{\\textbf{|w|}^2})}\n",
    "\\end{align}\n",
    "\n",
    "where $\\tau$ denotes the iteration number, and ${\\eta}^{(\\tau)}$is a learning rate parameter.\n",
    "\n",
    "So the stochastic gradient learning gradient is as follows:\n",
    "\n",
    "- Initialize the parameter $\\large{\\textbf{w}}$ to some starting vector $\\large{\\textbf{w}^{(0)}}$ and $\\large{\\tau = 1}$\n",
    "- While stopping condition is not met do:\n",
    "    - randomly select a datapoint $(x_{n}, y_{n})$ from training dataset\n",
    "    - $\\large{\\textbf{w}^{(\\tau)} := \\textbf{w}^{(\\tau-1)} - {\\eta}^{(\\tau)}{\\nabla} (E_{n}(\\textbf{w}^{(\\tau)})+ \\frac{\\lambda}{2}{\\textbf{|w|}^2})} \\\\\n",
    "    \\implies \\large{\\textbf{w}^{(\\tau)} := \\textbf{w}^{(\\tau-1)} - {\\eta}^{(\\tau)}({\\nabla}E_{n}(\\textbf{w}^{(\\tau)})+ {\\lambda}{\\textbf{|w|}})}$\n",
    "    - $\\large{\\tau = \\tau + 1}$\n",
    "\n",
    "\n",
    "$\\large{\\tau}$ here refers to visiting a single training datapoint in Stochastic GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "library(ggplot2) # for plots\n",
    "library(reshape2) # for data reshaping\n",
    "library(repr) \n",
    "library(tidyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "read_data <- function(fname, sc) {\n",
    "   data <- read.csv(file=fname,head=TRUE,sep=\",\")\n",
    "   nr = dim(data)[1]\n",
    "   nc = dim(data)[2]\n",
    "   x = data[1:nr,1:(nc-1)]\n",
    "   y = data[1:nr,nc]\n",
    "   if (isTRUE(sc)) {\n",
    "      x = scale(x)\n",
    "      y = scale(y)\n",
    "   }\n",
    "   return (list(\"x\" = x, \"y\" = y))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function to calculate labels based on the estimated coefficients\n",
    "\n",
    "# auxiliary function to calculate labels based on the estimated coefficients\n",
    "predict_func <- function(Phi, w){\n",
    "    return(Phi%*%w)\n",
    "} \n",
    "\n",
    "# auxiliary function to calculate the objective function for the training\n",
    "train_obj_func <- function (Phi, w, label, lambda){\n",
    "    # the L2 regulariser is already included in the objective function for training \n",
    "    return(.5 * (mean((predict_func(Phi, w) - label)^2)) + .5 * lambda * w %*% w)\n",
    "}\n",
    "\n",
    "# auxiliary function to compute the error of the model\n",
    "get_errors <- function(train_data, test_data, W) {\n",
    "    n_weights = dim(W)[1]\n",
    "    errors = matrix(,nrow=n_weights, ncol=2)\n",
    "    for (tau in 1:n_weights) {\n",
    "        errors[tau,1] = train_obj_func(train_data$x, W[tau,],train_data$y, 0)\n",
    "        errors[tau,2] = train_obj_func(test_data$x, W[tau,],test_data$y, 0)\n",
    "    }\n",
    "    return(errors)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_train <- function(train_x, train_y, lambda, eta, epsilon, max_epoch) {\n",
    "   set.seed(123)\n",
    "    \n",
    "   train_len = dim(train_x)[1]\n",
    "   tau_max = max_epoch * train_len\n",
    "\n",
    "   W <- matrix(,nrow=tau_max, ncol=ncol(train_x)) \n",
    "   W[1,] <- runif(ncol(train_x))\n",
    "  \n",
    "   tau = 1 # counter \n",
    "   obj_func_val <-matrix(,nrow=tau_max, ncol=1) \n",
    "   obj_func_val[tau,1] = train_obj_func(train_x, W[tau,],train_y, lambda)\n",
    "\n",
    "   while (tau <= tau_max){\n",
    "\n",
    "       # check termination criteria\n",
    "       if (obj_func_val[tau,1]<=epsilon) {break}\n",
    " \n",
    "       # shuffle data:\n",
    "       train_index <- sample(1:train_len, train_len, replace = FALSE)\n",
    "    \n",
    "       # loop over each datapoint\n",
    "       for (i in train_index) {\n",
    "           # increment the counter\n",
    "           tau <- tau + 1\n",
    "           if (tau > tau_max) {break}\n",
    "\n",
    "           # make the weight update\n",
    "           y_pred <- predict_func(train_x[i,], W[tau-1,])\n",
    "           W[tau,] <- sgd_update_weight(W[tau-1,], train_x[i,], train_y[i], y_pred, lambda, eta)\n",
    "\n",
    "           # keep track of the objective funtion\n",
    "           obj_func_val[tau,1] = train_obj_func(train_x, W[tau,],train_y, lambda)\n",
    "       }\n",
    "   }\n",
    "   # final value for training objective function and weights\n",
    "   return(list('vals'=obj_func_val,'W'=W))\n",
    "}\n",
    "\n",
    "# update the weight vector\n",
    "sgd_update_weight <- function(W_prev, x, y_true, y_pred, lambda, eta) {\n",
    "   # add regularisation\n",
    "   grad = -as.vector(y_true-y_pred) * x + lambda * W_prev\n",
    "   # update weight\n",
    "   updated_weight <- W_prev - eta * grad\n",
    "    return (updated_weight)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train <- read_data('Data//1C_train.csv',TRUE)\n",
    "test <- read_data('Data//1C_test.csv',TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "\n",
    "# maximum number of iteration\n",
    "max_epoch <- 20 \n",
    "# a threshold on the cost \n",
    "epsilon <- .001 \n",
    "# learning rate\n",
    "eta <- .01\n",
    "#lambda\n",
    "lambdas <- (0:25)*0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each lambda in {0, 0.4, 0.8, â€¦, 10}, lets build a regression model and compute the training and testing errors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table error\n",
    "error.table <- data.frame(matrix(ncol = 3, nrow = 0))\n",
    "\n",
    "for (l in lambdas) { #loop over each value of lambdas\n",
    "    # training with given value of lambdas\n",
    "    fit <- sgd_train(train$x, train$y, lambda = l, eta = 0.01, epsilon = 0.001, max_epoch= 20)    \n",
    "    # Create dataframe to store error value\n",
    "    test_error <- data.frame(0)\n",
    "    \n",
    "    # transform value of lambdas into log lambda\n",
    "    test_error[\"log_lambdas\"] = log(l)\n",
    "    \n",
    "    # get value of the last epoch\n",
    "    test_error[\"train error\"] = tail(get_errors(train, test, fit$W),1)[1]\n",
    "    test_error[\"test error\"] = tail(get_errors(train, test, fit$W),1)[2]\n",
    "    \n",
    "    # adding error to table error\n",
    "    error.table <- rbind(error.table, test_error)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAZlBMVEUAAAAAAP8Av8QzMzNH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\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mintest = min(error.table[\"test error\"]) #spotting the lowest error\n",
    "# plot errors\n",
    "error.table %>%\n",
    "    gather(key, error ,\"train error\",\"test error\") %>%\n",
    "    ggplot(aes(x=log_lambdas, y = error, colour = key)) +\n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    geom_vline(xintercept = error.table[which(error.table[\"test error\"] == mintest),\"log_lambdas\"], linetype=\"dashed\", color = \"blue\") +\n",
    "    annotate(\"text\", x = error.table[which(error.table[\"test error\"] == mintest),\"log_lambdas\"]+0.1, y = mintest-0.01, label = exp(error.table[which(error.table[\"test error\"] == mintest),\"log_lambdas\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best value of lambda is **1.6**\n",
    "\n",
    "Model with higher complexity tend to be overfitting, which we can be seen when lambda=0 due to high test error and relatively low train error. As lambda increases, the model complexity decreases and we see increase in training error. This leads to making model less complex. So for larger value of lambda the model underfits (high test and high train error).\n",
    "\n",
    "The testing error decreases to some point and then increases with inrease in value of lambda. Here when **$\\lambda=1.6$** the model has least testing error hence its the best value of lambda as it is said to have generalized better at this value of $\\lambda$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
